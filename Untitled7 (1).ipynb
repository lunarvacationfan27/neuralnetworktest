{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e15f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 14:08:23.651071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/jon/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_img' from 'keras.preprocessing.image' (/Users/jon/opt/anaconda3/lib/python3.9/site-packages/keras/preprocessing/image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_img;\n\u001b[1;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m load_img(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/jon/Downloads/archive (4)/test_set/test_set/cats/cat.4001.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m img\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_img' from 'keras.preprocessing.image' (/Users/jon/opt/anaconda3/lib/python3.9/site-packages/keras/preprocessing/image.py)"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import load_img;\n",
    "\n",
    "print('test')\n",
    "img = load_img('/Users/jon/Downloads/archive (4)/test_set/test_set/cats/cat.4001.jpg')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c4947dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29932, 89)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_excel('/Users/jon/Desktop/default of credit card clients.xls',\n",
    "                  header=1)\n",
    "\n",
    "df = pd.read_excel('/Users/jon/Desktop/default of credit card clients.xls',\n",
    "                  header=1)\n",
    "\n",
    "df.rename({'default payment next month' : 'DEFAULT'}, axis='columns', inplace=True)\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "df_no_missing = df.loc[(df['EDUCATION'] != 0) & (df[\"MARRIAGE\"] != 0)]\n",
    "\n",
    "X = df_no_missing.drop('DEFAULT', axis=1).copy()\n",
    "\n",
    "y = df_no_missing['DEFAULT'].copy()\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['SEX',\n",
    "                                      'EDUCATION',\n",
    "                                      'MARRIAGE',\n",
    "                                      'PAY_0',\n",
    "                                      'PAY_2',\n",
    "                                      'PAY_3',\n",
    "                                      'PAY_4',\n",
    "                                      'PAY_5',\n",
    "                                      'PAY_6'])\n",
    "\n",
    "\n",
    "y = pd.get_dummies(y, columns=['DEFAULT'])\n",
    "\n",
    "X_array = np.asarray(X_encoded)\n",
    "X_array.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57577cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/gf9_5ckj7j5_tfcl4v4rflgw0000gn/T/ipykernel_15066/2010204478.py:62: RuntimeWarning: overflow encountered in add\n",
      "  b_i_h += -learn_rate * delta_h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 46.67\n",
      "Acc: 50.0\n",
      "Acc: 50.0\n",
      "Acc: 50.0\n",
      "Acc: 50.0\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "import skimage.io\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00001/02-06-2002-NA-BRAINROUTINE-33106/2.000000-t2Flairaxial ProcessedCaPTk-17693/*.dcm'))\n",
    "img2 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00003/04-16-2003-NA-BRAINROUTINE-22500/2.000000-t2Flairaxial ProcessedCaPTk-31001/*.dcm'))\n",
    "img3 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00002/11-13-2001-NA-BRAINROUTINE-48890/7.000000-t2Flairaxial ProcessedCaPTk-17963/*.dcm'))\n",
    "img4 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00004/08-23-2002-NA-MRI BRAIN WINJMHDI-01520/12.000000-t2Flairaxial ProcessedCaPTk-57782/*.dcm'))\n",
    "\n",
    "images = np.concatenate((img, img2))\n",
    "\n",
    "images2 = np.empty((120, 3072), dtype = np.float128)\n",
    "labels = np.empty((120, 2))\n",
    "\n",
    "for i in range(0, 119):\n",
    "    images2[i] = skimage.transform.rescale(images[i], 0.25, anti_aliasing=True).flatten()\n",
    "\n",
    "for i in range(0, 59):\n",
    "    labels[i] = np.array([1, 0])\n",
    "\n",
    "for i in range(60, 119):\n",
    "    labels[i] = np.array([0, 1])\n",
    "\n",
    "images = images2\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(images)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "\n",
    "w_i_h = np.random.uniform(-0.5, 0.5, (80, 3072))\n",
    "w_h_h = np.random.uniform(-0.5, 0.5, (20, 250))\n",
    "w_h_o = np.random.uniform(-0.5, 0.5, (2, 80))\n",
    "b_i_h = np.zeros((80, 1))\n",
    "b_h_h = np.zeros((20, 1))\n",
    "b_h_o = np.zeros((2, 1))\n",
    "\n",
    "learn_rate = 0.01\n",
    "nr_correct = 0\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for img, l in zip(images, labels):\n",
    "        img.shape += (1,)\n",
    "        l.shape += (1,)\n",
    "        h_pre = b_i_h + w_i_h @ img\n",
    "        h = 1 / (1 + np.exp(-h_pre))\n",
    "\n",
    "        o_pre = b_h_o + w_h_o @ h\n",
    "        o = 1 / (1 + np.exp(-o_pre))\n",
    "\n",
    "        e = 1 / len(o) * np.sum((o - l) ** 2, axis = 0)\n",
    "        nr_correct += int(np.argmax(o) == np.argmax(l))\n",
    "\n",
    "        delta_o = o - l\n",
    "        w_h_o += -learn_rate * delta_o @ np.transpose(h)\n",
    "        b_h_o += -learn_rate * delta_o\n",
    "        delta_h = np.transpose(w_h_o) @ delta_o * (h * (1 - h))\n",
    "        w_i_h += -learn_rate * delta_h @ np.transpose(img)\n",
    "        b_i_h += -learn_rate * delta_h\n",
    "    \n",
    "    print(f\"Acc: {round((nr_correct/images.shape[0]) * 100, 2)}\")\n",
    "    nr_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_excel('/Users/jon/Desktop/default of credit card clients.xls',\n",
    "                  header=1)\n",
    "\n",
    "df.rename({'default payment next month' : 'DEFAULT'}, axis='columns', inplace=True)\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "df_no_missing = df.loc[(df['EDUCATION'] != 0) & (df[\"MARRIAGE\"] != 0)]\n",
    "\n",
    "df_no_default = df_no_missing[df_no_missing['DEFAULT'] == 0]\n",
    "df_default = df_no_missing[df_no_missing['DEFAULT'] == 1]\n",
    "\n",
    "df_no_default_downsampled = resample(df_no_default,\n",
    "                                    replace=False,\n",
    "                                    n_samples=1000,\n",
    "                                    random_state=42)\n",
    "\n",
    "df_default_downsampled = resample(df_default,\n",
    "                                    replace=False,\n",
    "                                    n_samples=1000,\n",
    "                                    random_state=42)\n",
    "\n",
    "df_downsample = pd.concat([df_no_default_downsampled, df_default_downsampled])\n",
    "\n",
    "X = df_downsample.drop('DEFAULT', axis=1).copy()\n",
    "\n",
    "y = df_downsample['DEFAULT'].copy()\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['SEX',\n",
    "                                      'EDUCATION',\n",
    "                                      'MARRIAGE',\n",
    "                                      'PAY_0',\n",
    "                                      'PAY_2',\n",
    "                                      'PAY_3',\n",
    "                                      'PAY_4',\n",
    "                                      'PAY_5',\n",
    "                                      'PAY_6'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "param_grid = [\n",
    "    {'C': [0.5, 1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "SVC(),\n",
    "param_grid,\n",
    "cv=5,\n",
    "scoring='accuracy',\n",
    "verbose=0\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train_scaled, y_train)\n",
    "print(optimal_params.best_params_)\n",
    "'''\n",
    "\n",
    "clf_svm = SVC(random_state = 42, C=100, gamma=0.001)\n",
    "clf_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "plot_confusion_matrix(clf_svm, \n",
    "                      X_test_scaled, \n",
    "                      y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=[\"Did not default\", \"Defaulted\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c42929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jon/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fd3eb006dc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkPklEQVR4nO3deZwV1Zn/8c+XVQXZl6CAoKK4RIlBxyUaXOKWGTETNRidGKNxX8ZE89PJ/KLGwRhNTDQOSUx0JC4obhOiM+ISjXEDEQ2yuKCgsq8uIAG6+5k/qlqubXff6r7ddN+u79tXvbruqapzTt+Lz60+deopRQRmZpYP7Vq6A2Zmtvk46JuZ5YiDvplZjjjom5nliIO+mVmOdGjpDljd+vRqH0MGdWzpblgDvDFjq5bugjXQR6xeERF9G3v8EQd3iZWrKjPt+9KM9ZMj4sjGttUUHPRbsSGDOjJ18qCW7oY1wBHbjGjpLlgDPR73vVPK8StWVTJl8sBM+3Yc8FafUtpqCg76ZmYlCSqjqqU7kZmDvplZCQKoonxucvWFXDOzElVl/K8YSYMkPSlpjqRZki5My3tJekzSm+nPngXHXCZprqTXJR1RrA0HfTOzEgTBxqjKtGRQAXw/InYB9gXOlbQrcCnwREQMA55IX5NuGwPsBhwJjJPUvr4GHPTNzEoQQCWRaSlaV8TiiJiern8EzAG2BUYD49PdxgPHpuujgbsjYn1EzAPmAvvU14bH9M3MStSAMf0+kqYVvL45Im6ubUdJQ4AvAFOA/hGxGJIvBkn90t22BV4oOGxBWlYnB30zsxIEUJk9W/GKiBhZbCdJXYH7gX+NiA8l1blrHV2qk4d3zMxKVJVxyUJSR5KAf2dEPJAWL5U0IN0+AFiWli8ACm/mGQgsqq9+B30zsxJExvH8LGP6Sk7pbwHmRMT1BZsmAaek66cAfywoHyOps6ShwDBgan1teHjHzKwEEbCx6abpHwD8C/CqpFfSsn8DrgEmSjoNeBc4Pmk7ZkmaCMwmmflzbkTUmxPCQd/MrCSistah9YaLiGeofZwe4NA6jhkLjM3ahoO+mVkJAqgqnxtyHfTNzErVVGf6m4ODvplZCZKbsxz0zcxyIYCNUT4TIR30zcxKEIjKMpr97qBvZlaiqvDwjplZLnhM38wsV0Slx/TNzPIheXKWg76ZWS5EiA1R73NLWhUHfTOzElV5TN/MLB+SC7ke3jEzywlfyDUzyw1fyDUzy5lK35xlZpYPgdgY5RNKy6enZmatkC/kmpnlSCAP75iZ5Ykv5JqZ5UQEZTVls3x6ambWCiUXcttnWoqRdKukZZJmFpSNkPSCpFckTZO0T8G2yyTNlfS6pCOy9NdB38ysRJW0y7RkcBtwZI2ya4ErI2IE8KP0NZJ2BcYAu6XHjJNU9JvFQd/MrASBqIpsS9G6Ip4GVn2mCeiWrncHFqXro4G7I2J9RMwD5gL7UITH9M3MStSAKZt9JE0reH1zRNxc5Jh/BSZL+hnJifr+afm2wAsF+y1Iy+rloG9mVoIAqrJfyF0RESMb2MTZwEURcb+kE4BbgMOg1tSeUawyD++YmZVEVGZcGukU4IF0/V42DeEsAAYV7DeQTUM/dXLQNzMrQUCTzd6pwyLgy+n6IcCb6fokYIykzpKGAsOAqcUq8/COmVkJItSQ4Z16SZoAjCIZ+18AXA58F7hBUgfg78AZSbsxS9JEYDZQAZwbEZXF2nDQNzMrUVPdnBURJ9ax6Yt17D8WGNuQNhz0zcxKkOTTd+4dM7Oc8JOzzMxyI5my6TN9M7NcqM69Uy4c9M3MSuTUymZmOZGkVvbwjplZbnhM38wsJ5Ismx7eMTPLhSQNg4O+5diyhR257sLBrF7WEbULjj55JV87fQUfrm7P1WcNYemCTvQfuIEf/nY+W/eoZMl7nfjul4czcPv1AAz/4lou/OmCFv4t8m38lNmsW9OeqiqorBDnH7UTp///Rez7lQ/ZuEEsfqcTP79oMGs/LJ9ZK83HZ/oASKoEXgU6kuSFGA/8MiKqJI0EvhURF9Ry3HxgZESsKLH9Y4E3ImJ2hn3XRETXIvtcQJLidHpEnNSI/swHRpK8F9+MiHENraNctO8QnPGjRQzbYx0fr2nHeUfuxF4HfcRj9/TiC1/6iG+cv4x7ftWPe27qx+n/vhiAAdut59ePv97CPbdCPzh+Bz5ctSlETH96a269egBVleK0Hy5izPlLuWXsNi3Yw9ajnO7Ibc6vp3URMSIidgO+AhxNkjyIiJhWW8BvYscCuzZhfecARzcm4NfQI62rzerdv4Jhe6wDYKuuVQzacT0rFnfk+cndOeyE5KFAh52wiucf6d6S3bQGmv6XramqTILbnJe60GfAxhbuUetQPXsny9IabJa/SSJiGUlmuPOUGCXpIQBJvSU9KullSb+l9gcDIGmNpLGS/pY+JLh/Wr6dpCckzUh/Dpa0P3AMcF36MOEdatQ1VNLzkl6UdFWNbZek5TMkXZmW/QbYHpgk6SJJ+0h6Lu3zc5J2Tvf7tqSbCup6SNKoGr/KNcAOab+ua+RbWjaWvNeJt2ZuyfC9Pmb1io707l8BJF8M76/cdBa55N1OnPOVnbj4n3fk1SldWqq7Vi3E1RPe5qZH3uCok1Z+ZvMRJ67ixT93q+XAfKqKdpmW1mCzjelHxNuS2gH9amy6HHgmIn4s6aukaUNr0QV4ISJ+KOlaknSj/wHcBPwhIsZL+g5wY0QcK2kS8FBE3FdLXTcAv46IP0g6t7pQ0uEkOan3IfnymSTpoIg4S9KRwMERsUJSN+CgiKiQdBhwNfD1jG/FpcDu6UOOP0PSGdXvweBty/uSy7q17bjq9CGc9eOFdNm6qs79evXbyB0vzqZbr0renLElV5w6lJufeq3eY6x5XTR6R1Yt7Uj33hu55u63eW9uZ2ZOSUZAT7xgKZUV8OcHerRsJ1uJ6mfklovN/dVT2ztzEHAHQEQ8DKyu49gNwEPp+kvAkHR9P+CudP124EsZ+nEAMKHgmGqHp8vLwHRgOMmXQE3dgXslzQR+QfI0+iYRETdHxMiIGNm3d/leJKvYCFedPoRD/nk1Xzr6AwB69tnIyqXJF9nKpR3o0Ts56+/UOejWK0kDPmyPdWwzZAML3+7cMh03AFYt7QjABys78uwj3Rn+hY8BOOz4Vexz2If89LztqOOP8twJoCLaZVpag83WC0nbA5XAslo2F32uI7AxIqr3q6Tuv1Ky1FXXfgJ+kl6LGBERO0bELbXsdxXwZETsDvwTsEVaXsGn39Mtah6YBxFw/fcHM2jYer5+5vJPyvc9/EMen9gLgMcn9mK/I5Ivg/dXtqcyffTD4nc6sXBeJz43eMNm77clOm9ZyZZdKj9Z/+KXP2L+a1swctSHnHDuMq749lDWr2sdAay18PBODZL6Ar8BboqIkD51hvA0cBLwH5KOAno2sPrngDEkZ+wnAc+k5R8BW9dxzLPpMXekx1SbDFwl6c6IWCNpW5Ivm5pfVN2Bhen6twvK5wPnpMNY27LpWZaF6utXmzBraheeuK8XQ3dZx9mH7QzAqZct4hvnLWXsWUN45O7e9Ns2mbIJ8OoLXfnDdZ+jfQdo3y644JoFdOtZ9AFA1kx69q3g8lvmA8lMrCcf7Mm0p7rxX8/OoWPn4Cf3vAXAay914cZLB7ZgT1uJKK/hneYM+ltKeoVNUzZvB66vZb8rgQmSpgN/Ad5tYDsXALdKugRYDpyalt8N/C6danlcRLxVcMyFwF2SLgTury6MiEcl7QI8n34xrQFO5rN/nVwLjJf0PeDPBeXPAvNIpqrOJBki+pSIWCnp2XRo6H8j4pIG/r6t3u7/sJbJi16pddtPJ771mbIDv/oBB371g2bulWW15N3OnP2VnT9TfuoBu7RAb1q/cnuIijaNmFhrM3LPLWLq5EHFd7RW44htRrR0F6yBHo/7XoqIkY09vufwfjHqluMz7fvfXxpXUltNoXUMMpmZlanqh6hkWYqRdKukZelIQGH5+ZJelzQrnb1YXX6ZpLnptiOy9Le85wSambWwQFRUNdn5822k09CrCyQdDIwG9oiI9ZL6peW7klyb3A3YBnhc0k4RUe8FMZ/pm5mVqAplWoqJiKeBVTWKzwauiYj16T7V1xhHA3dHxPqImAfMpfbJI5/ioG9mVopo0PBOH0nTCpa6bkYttBNwoKQpkv4iae+0fFvgvYL9FqRl9fLwjplZCRr4YPQVjbiQ24FkKvu+wN7AxPS+p9oaLTozx0HfzKxEzTxPfwHwQHpz6lRJVUCftLxwet9AYFGxyjy8Y2ZWgkBUVrXLtDTSfwOHAEjaCegErAAmAWMkdZY0lCRlzNRilflM38ysRE11c5akCcAokrH/BSQJKW8luQF1JkkOslPSs/5ZkiYCs0lugD232MwdcNA3MytJRNMN70TEiXVsOrmO/ccCYxvShoO+mVmJwrl3zMzywgnXzMxyxWf6ZmY5EQGVVQ76Zma5UU6plR30zcxKEHh4x8wsR3wh18wsV8rpWVQO+mZmJfLwjplZTiSzd8onjZmDvplZiTy8Y2aWIx7eMTPLiUAO+mZmeVJGozsO+mZmJQkIp2EwM8sPD++YmeVIm5i9I+lX1DNUFREXNEuPzMzKSFvKvTNts/XCzKxcBdAWgn5EjC98LalLRKxt/i6ZmZWXchreKXrvsKT9JM0G5qSv95Q0rtl7ZmZWFkRUZVuK1iTdKmmZpJm1bLtYUkjqU1B2maS5kl6XdESW3mZJGPFL4AhgJUBE/A04KEvlZma5EBmX4m4DjqxZKGkQ8BXg3YKyXYExwG7pMeMktS/WQKYsQRHxXo2iyizHmZm1eZFcyM2yFK0q4mlgVS2bfgH8gE9/dYwG7o6I9RExD5gL7FOsjSxB/z1J+wMhqZOki0mHeszMjIac6feRNK1gOaNY1ZKOARamoyyFtgUKT8gXpGX1yjJP/yzghrSyhcBk4NwMx5mZ5UTm2TsrImJk5lqlrYAfAodnbLToIFLRoB8RK4CTivbOzCyvqpqt5h2AocDfJAEMBKZL2ofkzH5Qwb4DgUXFKswye2d7SX+StDy9qvxHSds3qvtmZm1N9Tz9LEtDq454NSL6RcSQiBhCEuj3ioglwCRgjKTOkoYCw4CpxerMMqZ/FzARGABsA9wLTGhw783M2qiIbEsxkiYAzwM7S1og6bS624xZJLF5NvAIcG5EFJ1kk2VMXxFxe8HrOySdl+E4M7N8aKKbsyLixCLbh9R4PRYY25A26su90ytdfVLSpcDdJL/aN4CHG9KImVmb1hbSMAAvkQT56t/mzIJtAVzVXJ0yMysnKqM0DPXl3hm6OTtiZlaWQtDWHqIiaXdgV2CL6rKI+ENzdcrMrKy0hTP9apIuB0aRBP3/AY4CngEc9M3MoKyCfpYpm8cBhwJLIuJUYE+gc7P2ysysnDRdwrVml2V4Z11EVEmqkNQNWAb45iwzM2g7D1EpME1SD+B3JDN61pDhri8zs7xoE7N3qkXEOenqbyQ9AnSLiBnN2y0zszLSFoK+pL3q2xYR05unS2Zm5aWtnOn/vJ5tARzSxH2xGuYs6Mt+F5/V0t2wBnj/Xj9Guuwcd1/pdbSFMf2IOHhzdsTMrCy1opk5WWS6OcvMzOrhoG9mlh9qvoeoNDkHfTOzUpXRmX6WJ2dJ0smSfpS+Hpw+qsvMLPcU2ZfWIEsahnHAfkB1cv+PgP9sth6ZmZWbZnpcYnPIMrzzDxGxl6SXASJitaROzdwvM7Py0UrO4rPIEvQ3SmpP+mtJ6ktzPvvdzKzMtJahmyyyDO/cCDwI9JM0liSt8tXN2iszs3IRyeydLEsxkm6VtEzSzIKy6yS9JmmGpAfTXGjV2y6TNFfS65KOyNLdokE/Iu4EfgD8BFgMHBsR92ap3MwsF5outfJtwJE1yh4Ddo+IPYA3gMsAJO0KjAF2S48Zl47K1CvL7J3BwMfAn4BJwNq0zMzMoMmCfkQ8DayqUfZoRFSkL18ABqbro4G7I2J9RMwD5gJFZ1ZmGdN/mE0PSN8CGAq8TvLtYmaWew0Y0+8jaVrB65sj4uYGNPUd4J50fVuSL4FqC9KyemVJrfz5wtdp9s0zs/fRzMxSKyJiZGMOlPRDoAK4s7qolt2Kfv00+I7ciJguae+GHmdm1mY18+wdSacA/wgcGhHVrS0ABhXsNhBYVKyuLA9G/17By3bAXsDyzL01M2vLonlz70g6Evh/wJcj4uOCTZOAuyRdD2wDDCPDUw2znOlvXbBeQTLGf3/mHpuZtXVNdKYvaQIwimTsfwFwOclsnc7AY5IAXoiIsyJilqSJwGyS2HxuRFQWa6PeoJ9O/+kaEZeU9JuYmbVRouluzoqIE2spvqWe/ccCYxvSRn2PS+wQERX1PTbRzMxoM2kYppKM378iaRJwL/DJs+Ai4oFm7puZWevXijJoZpFlTL8XsJLkmbjV8/UDcNA3M4OyykZWX9Dvl87cmcmmYF+tjL7XzMyaV1s5028PdKWRNwCYmeVGGUXE+oL+4oj48WbriZlZOcqeTK1VqC/ot47HvJiZtXJtZXjn0M3WCzOzctYWgn5ErKprm5mZbdKcaRiaWoMTrpmZWYE2NKZvZmZFiPK6AOqgb2ZWKp/pm5nlR1uZvWNmZlk46JuZ5UQzP0SlqTnom5mVymf6Zmb54TF9M7M8cdA3M8uPcjrTb9fSHTAzK2tB8hCVLEsRkm6VtEzSzIKyXpIek/Rm+rNnwbbLJM2V9LqkI7J010HfzKwE1Q9Gz7JkcBtwZI2yS4EnImIY8ET6Gkm7AmOA3dJjxklqX6wBB30zs1JFxqVYNRFPAzWTXY4Gxqfr44FjC8rvjoj1ETEPmAvsU6wNB30zsxIpItPSSP0jYjFA+rNfWr4t8F7BfgvSsnr5Qq6ZWSkalmWzj6RpBa9vjoibG9lyox5l66BvZlaiBszeWRERIxtY/VJJAyJisaQBwLK0fAEwqGC/gcCiYpV5eMfMrESqyrY00iTglHT9FOCPBeVjJHWWNBQYBkwtVpnP9M3MStVE8/QlTQBGkQwDLQAuB64BJko6DXgXOB4gImZJmgjMBiqAcyOislgbDvpmZqXIPh2zeFURJ9axqdZnlkfEWGBsQ9pw0DczK1UZ3ZHroG9mVoLqm7PKhYO+mVmJVFU+Ud9B38ysFA2bp9/iHPSt2Z3wpVc5Zt85CJg0ZTj3/HUPAI47YCbHHTCTyqp2PDdnMP/58L4t29Ec6zVuAVu+9CGV3Tuw5PqdPrVt60nL6Xn7EhbcsgtV3Tqw1V9X0+2PKz7Z3vHdv7PkpzuyceiWm7vbrYafnLUZSaoEXgU6kkxbGg/8MiLq/RgkXQccDfxPRFzSiHbXRERXSUOA/SPirgYefxvwUETc19C2y8n2n1vFMfvO4bQbvkZFZXt+cfr/8Oyc7ejXfQ0H7Taff/n58WysbE/Prutauqu5tnZUTz46sje9b3rvU+XtV2xgixlrqOjT8ZOyjw/syccHJokeO77zd/peOz/XAR/wmf5mti4iRgBI6gfcBXQnmd9anzOBvhGxvsT2hwDfTNu1Gob0W82sd/qzfmMSNF5+ewBf3n0euwxazu1PjmBjZZIUcPWanAeNFrZ+1y60X7bhM+U9b1vM+yd/jr7XvlPrcVs9+z5rD+jRzL1r/crpQm6buiM3IpYBZwDnKdFe0nWSXpQ0Q9KZAJImAV2AKZK+IemfJE2R9LKkxyX1T/e7QtLF1fVLmpme2Re6BjhQ0iuSLqqnTUm6SdJsSQ+zKWlSm/bWkl6M2H4x3bb6O507bmS/4e/Sv8caBvX5gD2HLub3FzzIuLMnscugZcUrs81qyxc/pLJXRzYOqfsLeavnPuDjL/XYfJ1qjQKIyLa0Am3hTP9TIuJtSe1Igupo4IOI2FtSZ+BZSY9GxDHp8MwIgPShBPtGREg6HfgB8P2MTV4KXBwR/5jWdUZtbQJfAHYGPg/0J7mL7taalaXHnwHQaaueNTeXnXeW9eSOJ0dw4xkP8/GGDsxd3JvKqna0b1/F1ltu4PQbj2XXQcv5j395nK9ffSK155CyzU3rq+j2wDKW/fvQOvfp9ObHRCexcfAWm7FnrZPH9FtedeQ4HNhD0nHp6+4k+Snm1dh/IHBPmsyoUy3bG6KuNg8CJqS3SS+S9OfaDk4z7t0M0KX3oNZxalCiP00dzp+mDgfgrKOmsOyDrgzpt5qnZg4FxOz3+lFVJXp0+Tvvr/UwT2vQYckGOizbwIBL3gSg/cqNfO4Hc1nykx2o6pkM1W317Ps+y8fz9FucpO2BSpJMdALOj4jJRQ77FXB9REySNAq4Ii2v4NNDYFlOaWptU9LRlNXlnqbTs+s6Vq/Zkv49PmLU5+fz3V8dS4QYueNCXn5rGwb1eZ+OHSp5f63PGFuLjdttwcJbdv3k9TbnvMaSa3akqlsaMqqCrZ7/gKU/3qGFetiKtKKhmyzaVNCX1Bf4DXBTOlQzGThb0p8jYqOknYCFEbG2xqHdgYXp+ikF5fOB6mGbvYDa/tb9CNi64HWtbQJPA2dK+gPJ0NPB5OTi79XfepTuXf5ORWU7fvbAAXy0rjN/mrozPzzhKe64eCIVFe256u6D8dBOy+n9y3fZYtZa2n1UwTZnzuGDE/qz9tBede7fec5aKnt3pLJ/p83Yy9bLZ/qb15aSXmHTlM3bgevTbb8nmV0zXZKA5Wx61FihK4B7JS0EXmBTcL8f+FZa/4vAG7UcOwOokPQ3kudb3lBHmw8Ch5BML30D+EtjftlydPa40Z8pq6hsz5UTas0hZS1g5b8Ornf7onHDP/V6/W5dWXr1js3ZpfLioL/5RESdDwJO5+r/W7rU3Na1YP2PbMpRXbjPOpIx+trq7pr+3MhnM+DV2iZwXl19NbPy5TN9M7O8CKCyfKK+g76ZWYl8pm9mlieevWNmlh8+0zczywunVjYzyw8BKqMLuW0q4ZqZWUtQRKYlU11J4sZZaYLHCZK2kNRL0mOS3kx/Njoxl4O+mVkpogFLEZK2BS4ARkbE7kB7YAxJYscnImIY8ET6ulEc9M3MSpIxrXL2GT4dSDINdAC2AhaRZAwen24fT+2ZBTJx0DczK5Ei2wL0kTStYDmjsJ6IWAj8DHgXWEySpv1RoH9ELE73WUwJz+PwhVwzs1JlP4tfEREj69qYjtWPJsn/9T5JTrCTS+5fAQd9M7NSRJPO3jkMmBcRywEkPQDsDyyVNCAiFqfP/Wj0o+Y8vGNmVqomupBLMqyzr6St0iy9hwJzgElsSvt+CrUkiMzKZ/pmZiXKOh2zmIiYIuk+YDpJqviXSZ6k1xWYKOk0ki+G4xvbhoO+mVmpmjD3TkRcDlxeo3g9n03h3igO+mZmpQjAD0Y3M8sHkf1u29bAQd/MrFRV5XOq76BvZlYKD++YmeWLh3fMzPLEQd/MLC8alEytxTnom5mVIoAyeoiKg76ZWYk8pm9mlicO+mZmORFAlYO+mVlO+EKumVm+OOibmeVEAJXlc0uug76ZWUkCwkHfzCw/PLxjZpYTnr1jZpYzPtM3M8uRMgr67Vq6A2ZmZS0CKiuzLRlI6iHpPkmvSZojaT9JvSQ9JunN9GfPxnbXQd/MrFQR2ZZsbgAeiYjhwJ7AHOBS4ImIGAY8kb5uFAd9M7NSNVHQl9QNOAi4Jak2NkTE+8BoYHy623jg2MZ21UHfzKwkkczeybJAH0nTCpYzalS2PbAc+C9JL0v6vaQuQP+IWAyQ/uzX2N76Qq6ZWSkCIvvNWSsiYmQ92zsAewHnR8QUSTdQwlBObXymb2ZWqsqqbEtxC4AFETElfX0fyZfAUkkDANKfyxrbVQd9M7NSREBVVbalaFWxBHhP0s5p0aHAbGAScEpadgrwx8Z218M7Zmalatp5+ucDd0rqBLwNnEpygj5R0mnAu8Dxja3cQd/MrESR4Sw+c10RrwC1jfsf2hT1O+ibmZXED1ExM8sPJ1wzM8uPACJjioXWwEHfzKwU4YeomJnlSnh4x8wsR8roTF9RRled80bScuCdlu5HM+gDrGjpTliDtOXPbLuI6NvYgyU9QvL+ZLEiIo5sbFtNwUHfNjtJ04rkH7FWxp9Z2+E0DGZmOeKgb2aWIw761hJubukOWIP5M2sjPKZvZpYjPtM3M8sRB30zsxxx0M8BSZWSXpE0S9LfJH1PUrt020hJN9Zx3HxJWecf19f+sZJ2zbjvmgz7XCBpjqQ7G9mf+ZL6SOoh6ZzG1NEa1fc5FznuuvSY6xrZ7pr05xBJ32zE8bdJOq4xbVvD+Y7cfFgXESMAJPUD7gK6A5dHxDRgWjO3fyzwEMkTgJrCOcBRETGvxHp6pHWNK7lHrUOdn3OR484E+kbE+hLbHwJ8M23XWimf6edMRCwDzgDOU2KUpIcAJPWW9KiklyX9FlBtdUhaI2lsejb5gqT+afl2kp6QNCP9OVjS/sAxwHXpWegONeoaKul5SS9KuqrGtkvS8hmSrkzLfgNsD0ySdJGkfSQ9l/b5uerHzEn6tqSbCup6SNKoGr/KNcAOab8adZbbWtXyObdPz+ir388zASRNAroAUyR9Q9I/SZqSvp+PF3y2V0i6uLp+STMlDanR7DXAgen7eVE9bUrSTZJmS3oY6Nf874hVc9DPoYh4m+Szr/k/2+XAMxHxBZJncg6uo4ouwAsRsSfwNPDdtPwm4A8RsQdwJ3BjRDyX1nVJRIyIiLdq1HUD8OuI2BtYUl0o6XBgGLAPMAL4oqSDIuIsYBFwcET8AngNOCjt84+AqxvwVlwKvJX265IGHFcWanzOpwEfpO/z3sB3JQ2NiGNI/0KIiHuAZ4B90/fzbuAHDWjyUuCvaV2/qKtN4GvAzsDnSf7t7N8Uv69l4+Gd/KrtLP4g4J8BIuJhSavrOHYDyXANwEvAV9L1/aqPB24Hrs3QjwOArxcc89N0/fB0eTl93ZXkS+DpGsd3B8ZLGkaS2rxjhjbzpPpzPhzYo2DsvDvJ+1lziGwgcI+kAUCnWrY3RF1tHgRMiIhKYJGkP5fQhjWQg34OSdoeqASWAbvU2Jzlxo2NsekGj0rq/neU9SaQ2vYT8JOI+G2RY68CnoyIr6XDDU+l5RV8+i/ZLTL2pc2o8TkLOD8iJhc57FfA9RExKR0OuyItb8z7WWubko4m+78Na2Ie3skZSX2B3wA3FQTuak8DJ6X7HQX0bGD1zwFj0vWTSIYKAD4Ctq7jmGdrHFNtMvAdSV3T/mybXpysqTuwMF3/dkH5fGCEpHaSBpEME9VUX7/KWi2f82TgbEkd0+07SepSy6GF7+cpBeXzgb3SY/cChtZybM33s642nwbGpGP+A4CDG/dbWmP4TD8ftpT0CsnQRwXJMMr1tex3JTBB0nTgL8C7DWznAuBWSZcAy4FT0/K7gd9JugA4rsa4/oXAXZIuBO6vLoyIRyXtAjwvCWANcDLJWWuha0mGd74HFA4TPEsyNPEqMBOYXrOzEbFS0rOSZgL/2wbG9ev7nH9PMrtmupI3dDnJrKqargDulbQQeIFNwf1+4Ftp/S8Cb9Ry7AygQtLfgNtIrtfU1uaDwCEkn80bJP/WbDNxGgYzsxzx8I6ZWY446JuZ5YiDvplZjjjom5nliIO+mVmOOOhbWdOmzJIzJd0raasS6vok26Ok36uezKBKchY1OH2A6shcWld5jX2KZiCtsf+n8uWYgYO+lb/qvDG7k6SHOKtwo6T2jak0Ik6PiPqygo7COWOsDDnoW1vyV2DH9Cz8SUl3Aa82JtujpKckjUzXj5Q0XUlW0SfSdA9nARelf2UcKKmvpPvTNl6UdEB6bKbMpYUk/bekl5TkuD+jxrafp315Ir3rFkk7SHokPeavkoY3ybtpbZLvyLU2QVIH4CjgkbRoH2D3iJiXBs4PImJvSZ2BZyU9CnyBTdke+5Pk+7+1Rr19gd+RZPKcJ6lXRKxSkuJ5TUT8LN3vLuAXEfGMpMEkKQh2YVPm0h9L+ipJuuNivpO2sSXwoqT7I2IlSXbT6RHxfUk/Sus+j+Sh5WdFxJuS/oHk+QCHNOJttBxw0LdyV516AJIz/VtIhl2mFjxkpZRsj/sCT1fXFRGr6ujHYcCuacoIgG6StiZ75tJCF0j6Wro+KO3rSqAKuCctvwN4IM1NtD9J6oTq4ztnaMNyykHfyt0nT4uqlga/tYVFND7bozLsA8lQ6X4Rsa6WvmTOdaIks+VhaV0fS3qKujNaRtru+zXfA7O6eEzf8qCUbI/PA19W8vAPJPVKy2tmlHyUZKiFdL8R6WpDM5d2B1anAX84yV8a1doB1X+tfJNk2OhDYJ6k49M2JGnPIm1YjjnoWx78nmS8fnqaUfO3JH/lPgi8SZLt8dfUku0xIpaTjMM/kGaPrB5e+RPwteoLuSQZRkemF4pns2kW0ZXAQUoylx5O8cyljwAdJM0geVbACwXb1gK7SXqJZMz+x2n5ScBpaf9mAaMzvCeWU86yaWaWIz7TNzPLEQd9M7MccdA3M8sRB30zsxxx0DczyxEHfTOzHHHQNzPLkf8D5khRjL9HfLQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_excel('/Users/jon/Desktop/default of credit card clients.xls',\n",
    "                  header=1)\n",
    "\n",
    "df.rename({'default payment next month' : 'DEFAULT'}, axis='columns', inplace=True)\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "df_no_missing = df.loc[(df['EDUCATION'] != 0) & (df[\"MARRIAGE\"] != 0)]\n",
    "\n",
    "df_no_default = df_no_missing[df_no_missing['DEFAULT'] == 0]\n",
    "df_default = df_no_missing[df_no_missing['DEFAULT'] == 1]\n",
    "\n",
    "df_no_default_downsampled = resample(df_no_default,\n",
    "                                    replace=False,\n",
    "                                    n_samples=1000,\n",
    "                                    random_state=42)\n",
    "\n",
    "df_default_downsampled = resample(df_default,\n",
    "                                    replace=False,\n",
    "                                    n_samples=1000,\n",
    "                                    random_state=42)\n",
    "\n",
    "df_downsample = pd.concat([df_no_default_downsampled, df_default_downsampled])\n",
    "\n",
    "X = df_downsample.drop('DEFAULT', axis=1).copy()\n",
    "\n",
    "y = df_downsample['DEFAULT'].copy()\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['SEX',\n",
    "                                      'EDUCATION',\n",
    "                                      'MARRIAGE',\n",
    "                                      'PAY_0',\n",
    "                                      'PAY_2',\n",
    "                                      'PAY_3',\n",
    "                                      'PAY_4',\n",
    "                                      'PAY_5',\n",
    "                                      'PAY_6'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "param_grid = [\n",
    "    {'C': [0.5, 1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "SVC(),\n",
    "param_grid,\n",
    "cv=5,\n",
    "scoring='accuracy',\n",
    "verbose=0\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train_scaled, y_train)\n",
    "print(optimal_params.best_params_)\n",
    "'''\n",
    "\n",
    "\n",
    "clf_svm = SVC(random_state = 42, C=100, gamma=0.001)\n",
    "clf_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "plot_confusion_matrix(clf_svm, \n",
    "                      X_test_scaled, \n",
    "                      y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=[\"Did not default\", \"Defaulted\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35666883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.io\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "img = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-0001*/*/*-t2Flairaxial ProcessedCaPTk-*/*.dcm'))\n",
    "img2 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-0002*/*/*-t2Flairaxial ProcessedCaPTk-*/*.dcm'))\n",
    "img3 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-0003*/*/*-t2Flairaxial ProcessedCaPTk-*/*.dcm'))\n",
    "\n",
    "images2 = np.empty((1620, 224, 224, 1))\n",
    "labels = np.empty((1620, 4))\n",
    "\n",
    "for i in range(0, 239):\n",
    "    test = skimage.transform.resize(images[i], (224, 224), anti_aliasing=True)\n",
    "    test.shape += (1,)\n",
    "    images2[i] = test\n",
    "\n",
    "    \n",
    "for i in range(0, 1620):\n",
    "    if (math.floor(i/60) in [0, 2, 3, 4, 5, 10, 11, 16, 17, 20, 23, 26]):\n",
    "        labels[i] = np.array([0, 1])\n",
    "    else:\n",
    "        labels[i] = np.array([1, 0])\n",
    "\n",
    "\n",
    "labels[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4596cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                 [2,5,-1,2],\n",
    "                 [-1.5, 2.7, 3.3, -0.8]])\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                  [0.5, -0.91, 0.26, -0.5],\n",
    "                  [-0.26, -0.27, 0.17, 0.87]])\n",
    "\n",
    "weights2 = np.array([[0.1, -0.14, 0.5],\n",
    "                   [-0.5, 0.12, -0.33],\n",
    "                   [-0.44, 0.73, -0.13]])\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "outputs1 = inputs @ np.array(weights).T + biases\n",
    "outputs2 = outputs2 @ np.array(weights2).T + biases2\n",
    "print(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 224, 224, 64)      640       \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,275,780\n",
      "Trainable params: 134,275,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3999 - accuracy: 0.2550\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22917, saving model to vgg16_1.h5\n",
      "100/100 [==============================] - 105s 1s/step - loss: 1.3999 - accuracy: 0.2550 - val_loss: 1.4176 - val_accuracy: 0.2292\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4064 - accuracy: 0.2400\n",
      "Epoch 2: val_accuracy did not improve from 0.22917\n",
      "100/100 [==============================] - 108s 1s/step - loss: 1.4064 - accuracy: 0.2400 - val_loss: 1.3970 - val_accuracy: 0.2292\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4040 - accuracy: 0.1500\n",
      "Epoch 3: val_accuracy did not improve from 0.22917\n",
      "100/100 [==============================] - 108s 1s/step - loss: 1.4040 - accuracy: 0.1500 - val_loss: 1.3929 - val_accuracy: 0.2083\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3920 - accuracy: 0.2850\n",
      "Epoch 4: val_accuracy did not improve from 0.22917\n",
      "100/100 [==============================] - 141s 1s/step - loss: 1.3920 - accuracy: 0.2850 - val_loss: 1.4216 - val_accuracy: 0.2083\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4005 - accuracy: 0.2550\n",
      "Epoch 5: val_accuracy did not improve from 0.22917\n",
      "100/100 [==============================] - 123s 1s/step - loss: 1.4005 - accuracy: 0.2550 - val_loss: 1.4258 - val_accuracy: 0.2083\n",
      "Epoch 6/100\n",
      " 16/100 [===>..........................] - ETA: 1:44 - loss: 1.4211 - accuracy: 0.2188"
     ]
    }
   ],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import skimage\n",
    "import skimage.io\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00001/02-06-2002-NA-BRAINROUTINE-33106/2.000000-t2Flairaxial ProcessedCaPTk-17693/*.dcm'))\n",
    "img2 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00003/04-16-2003-NA-BRAINROUTINE-22500/2.000000-t2Flairaxial ProcessedCaPTk-31001/*.dcm'))\n",
    "img3 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00002/11-13-2001-NA-BRAINROUTINE-48890/7.000000-t2Flairaxial ProcessedCaPTk-17963/*.dcm'))\n",
    "img4 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00004/08-23-2002-NA-MRI BRAIN WINJMHDI-01520/12.000000-t2Flairaxial ProcessedCaPTk-57782/*.dcm'))\n",
    "\n",
    "images = np.concatenate((img, img2, img3, img4))\n",
    "\n",
    "images2 = np.empty((240, 224, 224, 1))\n",
    "labels = np.empty((240, 4))\n",
    "\n",
    "for i in range(0, 240):\n",
    "    test = skimage.transform.resize(images[i], (224, 224), anti_aliasing=True)\n",
    "    test.shape += (1,)\n",
    "    images2[i] = test\n",
    "\n",
    "for i in range(0, 60):\n",
    "    labels[i] = np.array([1, 0, 0, 0])\n",
    "\n",
    "for i in range(60, 120):\n",
    "    labels[i] = np.array([0, 1, 0, 0])\n",
    "\n",
    "for i in range(120, 180):\n",
    "    labels[i] = np.array([0, 0, 1, 0])\n",
    "    \n",
    "for i in range(180, 240):\n",
    "    labels[i] = np.array([0, 0, 0, 1])\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(images2)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4,activation=\"softmax\"))\n",
    "\n",
    "opt = SGD(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=\"epoch\")\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model.fit(x=images2, y=labels, steps_per_epoch=100, validation_steps=5, validation_split=0.2, epochs=100, callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "644a28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/gf9_5ckj7j5_tfcl4v4rflgw0000gn/T/ipykernel_30549/1399585888.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test = np.array([[2,5], [3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[2,5], [3]])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c737fb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2830201818.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    git init\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2654640e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image dimensions must agree.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/skimage/io/collection.py:60\u001b[0m, in \u001b[0;36mconcatenate_images\u001b[0;34m(ic)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     array_cat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m img5 \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00026/*/*-t2Flairaxial ProcessedCaPTk-*/*.dcm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m img5\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/skimage/io/collection.py:62\u001b[0m, in \u001b[0;36mconcatenate_images\u001b[0;34m(ic)\u001b[0m\n\u001b[1;32m     60\u001b[0m     array_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_images)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage dimensions must agree.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_cat\n",
      "\u001b[0;31mValueError\u001b[0m: Image dimensions must agree."
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "img5 = skimage.io.concatenate_images(skimage.io.imread_collection('/Users/jon/Desktop/manifest-1669766397961/UPENN-GBM/UPENN-GBM-00026/*/*-t2Flairaxial ProcessedCaPTk-*/*.dcm'))\n",
    "img5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
